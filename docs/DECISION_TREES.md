---
title: "Shared Decision Trees"
description: "Systematic decision-making frameworks for Calm projects"
version: "1.0"
last_updated: "2025-11-01"
---

# Shared Decision Trees

Systematic frameworks for consistent decision-making across calm-couples, calm-ai-project-manager, and qa-automation.

---

## 1. Feature Development: Build or Skip?

**Use when**: Deciding whether to implement a requested feature.

```
START: Feature Request
â”‚
â”œâ”€ Is it a user-blocking issue?
â”‚  â”œâ”€ YES â†’ BUILD (priority)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Does it align with core product mission?
â”‚  â”œâ”€ YES â†’ Continue
â”‚  â””â”€ NO â†’ SKIP (document reason)
â”‚
â”œâ”€ Token cost estimate < 5K?
â”‚  â”œâ”€ YES â†’ Continue
â”‚  â””â”€ NO â†’ Break into smaller features
â”‚
â”œâ”€ Can existing users do 80% of this with current features?
â”‚  â”œâ”€ YES â†’ SKIP (consider UX improvement instead)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Would this create technical debt?
â”‚  â”œâ”€ YES â†’ Plan cleanup task â†’ BUILD
â”‚  â””â”€ NO â†’ Continue
â”‚
â””â”€ DECISION: BUILD â†’ Create task â†’ Track costs
```

**Example**:
- Feature: "Dark mode toggle"
  - Blocking? No
  - Aligns with mission? Yes (UX improvement)
  - < 5K tokens? Yes (2K estimated)
  - Can users work around it? Yes (use browser dark mode)
  - Tech debt? No
  - **Decision**: SKIP (low priority, high user workaround)

---

## 2. Bug Priority: Critical vs Nice-to-Have?

**Use when**: Triaging bugs to determine what to fix first.

```
START: Bug Report
â”‚
â”œâ”€ Is it a production blocker? (user can't use app)
â”‚  â”œâ”€ YES â†’ CRITICAL (fix today)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Does it affect multiple users?
â”‚  â”œâ”€ YES â†’ HIGH
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Is there a simple workaround?
â”‚  â”œâ”€ YES â†’ MEDIUM (document workaround)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Will this get worse if ignored? (e.g., data corruption)
â”‚  â”œâ”€ YES â†’ HIGH (fix soon)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Fix cost < 3K tokens?
â”‚  â”œâ”€ YES â†’ MEDIUM (acceptable cost)
â”‚  â””â”€ NO â†’ LOW (defer until next sprint)
â”‚
â””â”€ DECISION: Log priority + create task
```

**Priority Levels**:
- ðŸ”´ CRITICAL: Production down, data at risk, multi-user impact
- ðŸŸ  HIGH: Affects specific user group, no workaround
- ðŸŸ¡ MEDIUM: Workaround exists, ~3K token fix cost
- ðŸŸ¢ LOW: Edge case, high fix cost, defer to later

---

## 3. Performance Issue: Debug or Accept?

**Use when**: Investigating slow operations or janky animations.

```
START: Performance Complaint
â”‚
â”œâ”€ What's the symptom?
â”‚  â”œâ”€ Slow API call (>2s)?
â”‚  â”‚  â”œâ”€ YES â†’ Go to "API Performance" tree
â”‚  â”‚  â””â”€ NO â†’ Continue
â”‚  â”œâ”€ Janky animation?
â”‚  â”‚  â”œâ”€ YES â†’ Go to "Animation Performance" tree
â”‚  â”‚  â””â”€ NO â†’ Continue
â”‚  â””â”€ Other?
â”‚     â””â”€ Go to "Generic Perf" tree
â”‚
â”œâ”€ Does it affect user experience?
â”‚  â”œâ”€ YES â†’ Continue (worth investigating)
â”‚  â””â”€ NO â†’ ACCEPT (not critical)
â”‚
â”œâ”€ Is this a known pain point?
â”‚  â”œâ”€ YES â†’ Reference PROJECT_PAIN_POINTS.md
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Can you reproduce it?
â”‚  â”œâ”€ YES â†’ Continue
â”‚  â””â”€ NO â†’ ACCEPT (intermittent, low priority)
â”‚
â””â”€ DECISION: CREATE PERF_ISSUE task â†’ Investigate
```

### API Performance Sub-tree

```
API Call > 2 seconds?
â”‚
â”œâ”€ Is it network latency?
â”‚  â”œâ”€ YES â†’ Can't optimize locally
â”‚  â”‚       Check Supabase status/RLS policies
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Is it a database query?
â”‚  â”œâ”€ YES â†’ N+1 query? Check indexes
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Is it external API (Stripe, etc)?
â”‚  â”œâ”€ YES â†’ Contact vendor support
â”‚  â””â”€ NO â†’ Continue
â”‚
â””â”€ SOLUTION: Add caching + loading state
```

### Animation Performance Sub-tree

```
Animation janky (< 60fps)?
â”‚
â”œâ”€ How many items?
â”‚  â”œâ”€ 1-5? â†’ Use React.memo
â”‚  â”œâ”€ 5-20? â†’ Add will-change CSS
â”‚  â””â”€ 20+? â†’ Virtualization required
â”‚
â”œâ”€ CSS 3D transforms?
â”‚  â”œâ”€ YES â†’ Reduce transforms + memoize
â”‚  â””â”€ NO â†’ Check state updates
â”‚
â””â”€ SOLUTION: Implement optimization â†’ Measure (DevTools)
```

---

## 4. Tech Stack Decision: Library X vs Library Y?

**Use when**: Deciding which tool/library to use for a task.

```
START: Need Library for Task
â”‚
â”œâ”€ Does Calm already use similar tool?
â”‚  â”œâ”€ YES â†’ USE EXISTING (consistency)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Is there a "Calm standard"?
â”‚  â”œâ”€ YES â†’ USE STANDARD
â”‚  â”‚       (React Query for data, Zustand for state, etc)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Check TOKEN_EFFICIENCY for recommendations?
â”‚  â”œâ”€ YES, documented? â†’ USE RECOMMENDED
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Compare: Learning curve vs time saved
â”‚  â”œâ”€ Library A: 30 min learn, 2 hours save â†’ RATIO 4:1
â”‚  â”œâ”€ Library B: 2 hours learn, 3 hours save â†’ RATIO 1.5:1
â”‚  â””â”€ Pick highest ratio (usually existing tool)
â”‚
â”œâ”€ Check bundle size impact?
â”‚  â”œâ”€ < 5KB gzip? â†’ Continue
â”‚  â”œâ”€ 5-20KB gzip? â†’ Acceptable for heavy lifting
â”‚  â””â”€ > 20KB gzip? â†’ REJECT (too large)
â”‚
â”œâ”€ Does it have good DevTools/debugging?
â”‚  â”œâ”€ YES â†’ Continue
â”‚  â””â”€ NO â†’ CONSIDER ALTERNATIVE
â”‚
â””â”€ DECISION: Document choice + add to standards doc
```

**Calm Standards** (use these first):
- **State**: Zustand (all projects)
- **Data Fetching**: React Query (React projects)
- **API Client**: TBD (calm-ai-pm uses custom)
- **Styling**: Tailwind CSS (React SaaS)
- **Testing**: Jest + React Testing Library (React)

---

## 5. Test Strategy: How Much Testing?

**Use when**: Deciding what level of test coverage to implement.

```
START: Writing Tests
â”‚
â”œâ”€ What's being tested?
â”‚  â”œâ”€ Critical business logic?
â”‚  â”‚  â””â”€ Write: Unit + Integration (90%+ coverage)
â”‚  â”œâ”€ UI component?
â”‚  â”‚  â””â”€ Write: Unit + Snapshot (70%+ coverage)
â”‚  â””â”€ E2E user flow?
â”‚     â””â”€ Write: E2E for happy path only
â”‚
â”œâ”€ Is this a known issue area?
â”‚  â”œâ”€ YES â†’ Add regression test + docs
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Would test save time in future?
â”‚  â”œâ”€ Catch: > 5 bugs over 6 months?
â”‚  â”‚  â””â”€ YES â†’ Worth testing
â”‚  â”œâ”€ Maintenance: Low (< 1 hour/month)?
â”‚  â”‚  â””â”€ Continue
â”‚  â””â”€ NO â†’ SKIP (high maintenance cost)
â”‚
â”œâ”€ Can test be flaky? (timing, device-specific)
â”‚  â”œâ”€ YES â†’ Don't E2E test
â”‚  â”‚       Use unit test instead
â”‚  â””â”€ NO â†’ Continue
â”‚
â””â”€ DECISION: Write test at appropriate level
```

**Test Levels** (cost vs confidence):

| Level | Cost | Confidence | Use For |
|-------|------|-----------|---------|
| Unit | 50 tokens | 60% | Logic, utilities, edge cases |
| Integration | 150 tokens | 80% | API calls, store updates |
| E2E | 300+ tokens | 95% | Critical user flows |
| Manual | 100 tokens | 70% | Edge cases, UI feel |

---

## 6. Cost Optimization: Where to Save Tokens?

**Use when**: Trying to reduce token usage for a task.

```
START: Want to Lower Cost
â”‚
â”œâ”€ Is cost > 10K tokens?
â”‚  â”œâ”€ YES â†’ Can you break into 2 smaller tasks?
â”‚  â”‚       Often YES â†’ Split it up
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Will the task repeat?
â”‚  â”œâ”€ YES â†’ Invest in patterns/templates (one-time cost)
â”‚  â”‚       These save 30-50% on future similar work
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Are you exploring or implementing?
â”‚  â”œâ”€ EXPLORING â†’ Use aggressive limiting:
â”‚  â”‚             grep before read, sample first
â”‚  â”œâ”€ IMPLEMENTING â†’ Use full context:
â”‚  â”‚                 builds, tests, detailed output
â”‚  â””â”€ Continue
â”‚
â”œâ”€ Check TOKEN_EFFICIENCY.md for your task type?
â”‚  â”œâ”€ YES â†’ Apply recommended strategies
â”‚  â””â”€ NO â†’ Use generic optimization
â”‚
â”œâ”€ Could you use async tools?
â”‚  â”œâ”€ YES (webhook, queue) â†’ Implement â†’ Save 20-30%
â”‚  â””â”€ NO â†’ Continue
â”‚
â””â”€ DECISION: Apply optimization â†’ Measure cost
```

**Quick Wins** (usually save 30-50%):
1. ðŸŽ¯ Ask specific questions before reading
2. ðŸŽ¯ Use grep before read
3. ðŸŽ¯ Sample first, read specific sections
4. ðŸŽ¯ Suppress verbose output
5. ðŸŽ¯ Use existing patterns/templates

---

## 7. Device Debugging: Test Local or Device?

**Use when**: Need to debug issue that might be device-specific (qa-automation).

```
START: Have Debugging Task
â”‚
â”œâ”€ Is it a web app issue? (HTML/CSS/JS)
â”‚  â”œâ”€ YES â†’ Test on local browser first
â”‚  â”‚       Use DevTools (faster, cheaper)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Is it mobile-specific?
â”‚  â”œâ”€ Touch gestures?
â”‚  â”‚  â””â”€ YES â†’ Device required
â”‚  â”œâ”€ Viewport size?
â”‚  â”‚  â””â”€ Maybe (can test with browser responsive mode)
â”‚  â””â”€ Continue
â”‚
â”œâ”€ Is it a native feature? (camera, geolocation, etc)
â”‚  â”œâ”€ YES â†’ Device required
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Can you mock the issue?
â”‚  â”œâ”€ YES â†’ Mock it â†’ Test locally â†’ Save 200% cost
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Device debugging cost > 5K?
â”‚  â”œâ”€ YES â†’ Plan it carefully
â”‚  â”‚       Minimize back-and-forth
â”‚  â””â”€ Continue
â”‚
â””â”€ DECISION: Local first â†’ Device only if needed
```

**Cost Breakdown** (qa-automation):
- Local debugging: 1-2K tokens
- Device debugging: +200% overhead (4-6K+ tokens)
- **Implication**: Test locally first, device as last resort

---

## 8. GDPR / Data Handling: How to Handle User Data?

**Use when**: Working with user data (calm-couples, calm-ai-pm).

```
START: Working with User Data
â”‚
â”œâ”€ Could this expose PII?
â”‚  â”œâ”€ YES â†’ Use RLS policies (Supabase)
â”‚  â”‚       Log all access
â”‚  â”‚       Document why you need access
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Could user request deletion?
â”‚  â”œâ”€ YES â†’ Implement cascade delete
â”‚  â”‚       Test deletion flow
â”‚  â”‚       Document in GDPR section
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Are you storing auth tokens?
â”‚  â”œâ”€ YES â†’ NEVER log tokens
â”‚  â”‚       Use .env or secrets manager
â”‚  â”‚       Rotate periodically
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Is this a database migration?
â”‚  â”œâ”€ YES â†’ Backup first
â”‚  â”‚       Test on staging
â”‚  â”‚       Have rollback plan
â”‚  â””â”€ NO â†’ Continue
â”‚
â””â”€ DECISION: Implement safely â†’ Document â†’ Review with team
```

---

## 9. Refactoring: When to Refactor vs Keep Going?

**Use when**: Tempted to refactor code.

```
START: Found Code to Refactor
â”‚
â”œâ”€ Is it blocking current work?
â”‚  â”œâ”€ YES â†’ Refactor as part of task
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Is it a known pain point?
â”‚  â”œâ”€ YES â†’ Schedule refactor task
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Would refactor reduce future token cost?
â”‚  â”œâ”€ > 20% savings? â†’ Refactor (invest time)
â”‚  â”œâ”€ 10-20% savings? â†’ Document + defer
â”‚  â””â”€ < 10% savings? â†’ SKIP (not worth it)
â”‚
â”œâ”€ Is code actively being changed?
â”‚  â”œâ”€ YES â†’ Refactor (reduce future conflicts)
â”‚  â””â”€ NO â†’ DEFER (no urgency)
â”‚
â”œâ”€ Refactor cost < 2K tokens?
â”‚  â”œâ”€ YES â†’ Do it
â”‚  â””â”€ NO â†’ HIGH COST (skip for now)
â”‚
â””â”€ DECISION: Refactor or Document + Defer
```

---

## 10. Documentation: When to Document?

**Use when**: Deciding how much to document.

```
START: Should You Document This?
â”‚
â”œâ”€ Is it project setup? (new developer onboarding)
â”‚  â”œâ”€ YES â†’ Document thoroughly (saves hours)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Is it a known pain point?
â”‚  â”œâ”€ YES â†’ Document solution (prevents future bugs)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Would docs reduce future token costs?
â”‚  â”œâ”€ YES â†’ Document (see TOKEN_EFFICIENCY.md)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Is this a common question?
â”‚  â”œâ”€ Answered same question 2+ times?
â”‚  â”‚  â””â”€ YES â†’ Document it
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Does it take < 15 min to write?
â”‚  â”œâ”€ YES â†’ Document it
â”‚  â””â”€ NO â†’ Document summary only
â”‚
â””â”€ DECISION: Document strategically
```

**Good Documentation Candidates**:
- Setup/onboarding
- Common errors + solutions
- Performance optimization techniques
- Architecture decisions
- Known issues + workarounds

---

## Using These Trees

### Workflow
1. **Identify the decision** being made
2. **Find matching tree** in this document
3. **Follow the path** answering each question
4. **Reach decision** at the end
5. **Document why** you chose this path

### Example
```
Decision: Should we add caching to API responses?

Tree: Performance Issue (Decision Tree #3)
â”œâ”€ Symptom: Slow API call > 2s
â”œâ”€ Affects UX: YES
â”œâ”€ Reproduce it: YES
â””â”€ Decision: CREATE PERF_ISSUE task

Then use Sub-tree: API Performance
â”œâ”€ Is it network latency? YES (Supabase)
â””â”€ Solution: Add caching + loading state

Implementation: Add Redis cache layer
Cost: 4K tokens
Expected savings: 200-300ms per request
```

---

## Adding New Trees

To add a decision tree for recurring decisions:

1. **Identify pattern**: What decision do you keep making?
2. **Document path**: What questions lead to decision?
3. **Add to this file**: Include tree diagram
4. **Reference**: Link from relevant places (AGENTS.md, etc)
5. **Test it**: Use the tree on 3 actual decisions
6. **Refine**: Adjust based on feedback

---

## See Also

- [AGENTS.md](../projects/calm-couples/AGENTS.md) - Project-specific guidance
- [TOKEN_EFFICIENCY.md](../docs/cost-optimization/TOKEN_EFFICIENCY.md) - Cost optimization
- [PROJECT_PAIN_POINTS.md](PROJECT_PAIN_POINTS.md) - Known issues
- Project READMEs - Cost baselines per project

---

**Version**: 1.0 | **Last Updated**: 2025-11-01 | **Reviewed**: Every feature/month
